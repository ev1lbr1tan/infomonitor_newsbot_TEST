import feedparser
import requests
from datetime import datetime, timedelta
import re
from typing import List, Dict, Optional
import logging

logger = logging.getLogger(__name__)

class EnhancedNewsCollector:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–±–æ—Ä–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –∏ –ø–µ—Ä–µ–≤–æ–¥–æ–º"""
    
    def __init__(self):
        # –°–ª–æ–≤–∞—Ä—å –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π)
        self.news_sources = {
            '–ø–æ–ª–∏—Ç–∏–∫–∞': {
                'ria': 'https://ria.ru/export/rss2/politics/index.xml',
                'tass': 'https://tass.ru/rss/v2.xml',
                'interfax': 'https://www.interfax.ru/rss.asp',
                'vedomosti': 'https://www.vedomosti.ru/rss/news.xml',
                'regnum': 'https://www.regnum.ru/feed',
                'gazeta': 'https://www.gazeta.ru/rss/articles.xml',
                'lenta': 'https://lenta.ru/rss/news',
                'vz': 'https://vz.ru/rssnews.xml',
                'novaya_gazeta': 'https://novayagazeta.ru/rss/articles.xml',
                'rt': 'https://www.rt.com/rss/all/'
            },
            '—ç–∫–æ–Ω–æ–º–∏–∫–∞': {
                'rbc': 'https://rssexport.rbc.ru/news/20/5001001/full.rss',
                'vedomosti': 'https://www.vedomosti.ru/rss/business.xml',
                'regnum': 'https://www.regnum.ru/feed',
                'kommersant': 'https://www.kommersant.ru/rss/economics.xml',
                'prime': 'https://1prime.ru/rss/',
                'forbes': 'https://forbes.ru/rss/feed.xml',
                'vc': 'https://vc.ru/rss',
                'bloomberg': 'https://feeds.bloomberg.com/markets/news.rss',
                'market_watch': 'http://feeds.marketwatch.com/marketwatch/marketpulse/',
                'financial_times': 'https://www.ft.com/rss/home'
            },
            '—Å–ø–æ—Ä—Ç': {
                'ria_sport': 'https://rsport.ria.ru/export/rss2/news/index.xml',
                'matchtv': 'https://matchtv.ru/rss/news.xml',
                'tass_sport': 'https://tass.ru/rss/v2.xml',
                'championat': 'https://www.championat.com/rss/news.xml',
                'sport_express': 'https://www.sport-express.ru/rss/news.xml',
                'eurosport': 'https://www.eurosport.ru/rss/all-news.xml',
                'espn': 'https://site.api.espn.com/apis/site/v2/sports/football/soccer/rss/news',
                'sky_sports': 'https://www.skysports.com/rss/12040',
                'goal': 'https://www.goal.com/rss/en/news',
                'bbc_sport': 'https://feeds.bbci.co.uk/sport/rss.xml'
            },
            '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏': {
                'habr': 'https://habr.com/ru/rss/articles/',
                'tadviser': 'https://www.tadviser.ru/rss.xml',
                'vc': 'https://vc.ru/rss',
                'techcrunch': 'https://techcrunch.com/feed/',
                'the_verge': 'https://www.theverge.com/rss/index.xml',
                'wired': 'https://www.wired.com/feed/rss',
                'arstechnica': 'http://feeds.arstechnica.com/arstechnica/index',
                'engadget': 'https://www.engadget.com/rss.xml',
                'mashable': 'https://mashable.com/feeds/rss/technology',
                'cnet': 'https://www.cnet.com/rss/news/'
            },
            '–º–∏—Ä–æ–≤—ã–µ': {
                'bbc': 'https://feeds.bbci.co.uk/news/rss.xml',
                'reuters': 'https://feeds.reuters.com/Reuters/worldNews',
                'cnn': 'http://rss.cnn.com/rss/edition.rss',
                'guardian': 'https://www.theguardian.com/world/rss',
                'ap': 'https://feeds.apnews.com/apf-worldnews',
                'npr': 'https://feeds.npr.org/1001/rss.xml',
                'wsj': 'https://feeds.a.dj.com/rss/RSSWorldNews.xml',
                'nyt': 'https://rss.nytimes.com/services/xml/rss/nyt/World.xml',
                'france24': 'https://www.france24.com/en/rss',
                'dw': 'https://rss.dw.com/rdf/rss-en'
            }
        }
        
        # –°–ª–æ–≤–∞—Ä—å –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–∏
        self.category_keywords = {
            '–ø–æ–ª–∏—Ç–∏–∫–∞': ['–ø–æ–ª–∏—Ç–∏–∫–∞', '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç', '–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ', '–¥–µ–ø—É—Ç–∞—Ç', '–ø–∞—Ä–ª–∞–º–µ–Ω—Ç', '–≤—ã–±–æ—Ä—ã', '–º–∏—Ç–∏–Ω–≥', '–ø—Ä–æ—Ç–µ—Å—Ç', '–≤–ª–∞—Å—Ç—å'],
            '—ç–∫–æ–Ω–æ–º–∏–∫–∞': ['—ç–∫–æ–Ω–æ–º–∏–∫–∞', '–±–∏—Ä–∂–∞', '–≤–∞–ª—é—Ç–∞', '—Ä—É–±–ª—å', '–¥–æ–ª–ª–∞—Ä', '–Ω–µ—Ñ—Ç—å', '–≥–∞–∑', '–±–∞–Ω–∫', '–∫—Ä–µ–¥–∏—Ç', '–∏–Ω—Ñ–ª—è—Ü–∏—è'],
            '—Å–ø–æ—Ä—Ç': ['—Å–ø–æ—Ä—Ç', '—Ñ—É—Ç–±–æ–ª', '—Ö–æ–∫–∫–µ–π', '–±–∞—Å–∫–µ—Ç–±–æ–ª', '—Ç–µ–Ω–Ω–∏—Å', '–æ–ª–∏–º–ø–∏–∞–¥–∞', '—á–µ–º–ø–∏–æ–Ω–∞—Ç', '–º–∞—Ç—á', '–∏–≥—Ä–æ–∫'],
            '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏': ['—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç', '—Ä–æ–±–æ—Ç', '–ø—Ä–æ–≥—Ä–∞–º–º–∞', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', '–≥–∞–¥–∂–µ—Ç', '—Å–º–∞—Ä—Ç—Ñ–æ–Ω', '–∏–Ω—Ç–µ—Ä–Ω–µ—Ç']
        }
    
    def clean_text(self, text: str, max_length: int = 200) -> str:
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç HTML —Ç–µ–≥–æ–≤ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã"""
        if not text:
            return ""
        
        # –£–¥–∞–ª–µ–Ω–∏–µ HTML —Ç–µ–≥–æ–≤
        clean = re.sub('<[^<]+?>', '', text)
        # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        clean = re.sub(r'\s+', ' ', clean).strip()
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã
        if len(clean) > max_length:
            clean = clean[:max_length].rsplit(' ', 1)[0] + '...'
        return clean
    
    def detect_category(self, title: str, description: str = "") -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
        text = (title + " " + description).lower()
        
        for category, keywords in self.category_keywords.items():
            if any(keyword in text for keyword in keywords):
                return category
        
        # –ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º "–º–∏—Ä–æ–≤—ã–µ"
        return "–º–∏—Ä–æ–≤—ã–µ"
    
    def get_news_by_category(self, categories: List[str], limit: int = 10) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
        all_news = []
        
        for category in categories:
            if category in self.news_sources:
                category_sources = self.news_sources[category]
                
                for source_name, url in category_sources.items():
                    try:
                        feed = feedparser.parse(url)
                        if feed.bozo == 0 and feed.entries:
                            for entry in feed.entries[:3]:  # –ë–µ—Ä–µ–º –ø–æ 3 –Ω–æ–≤–æ—Å—Ç–∏ —Å –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                                detected_category = self.detect_category(
                                    entry.get('title', ''), 
                                    entry.get('description', '')
                                )
                                
                                news_item = {
                                    'title': self.clean_text(entry.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞')),
                                    'description': self.clean_text(entry.get('description', '–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')),
                                    'link': entry.get('link', ''),
                                    'source': f"{source_name.upper()} ({category})",
                                    'category': detected_category,
                                    'published': entry.get('published', ''),
                                    'published_parsed': entry.get('published_parsed', None),
                                    'original_language': self.detect_language(entry.get('title', '') + ' ' + entry.get('description', ''))
                                }
                                all_news.append(news_item)
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {source_name} (–∫–∞—Ç–µ–≥–æ—Ä–∏—è {category}): {e}")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        all_news.sort(key=lambda x: x.get('published_parsed') or (0, 0, 0, 0, 0, 0), reverse=True)
        
        return all_news[:limit]
    
    def get_all_news(self, limit: int = 15) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        all_news = []
        
        for category, sources in self.news_sources.items():
            for source_name, url in sources.items():
                try:
                    feed = feedparser.parse(url)
                    if feed.bozo == 0 and feed.entries:
                        for entry in feed.entries[:2]:  # –ë–µ—Ä–µ–º –ø–æ 2 –Ω–æ–≤–æ—Å—Ç–∏ —Å –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                            detected_category = self.detect_category(
                                entry.get('title', ''), 
                                entry.get('description', '')
                            )
                            
                            news_item = {
                                'title': self.clean_text(entry.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞')),
                                'description': self.clean_text(entry.get('description', '–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')),
                                'link': entry.get('link', ''),
                                'source': f"{source_name.upper()}",
                                'category': detected_category,
                                'published': entry.get('published', ''),
                                'published_parsed': entry.get('published_parsed', None),
                                'original_language': self.detect_language(entry.get('title', '') + ' ' + entry.get('description', ''))
                            }
                            all_news.append(news_item)
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {source_name}: {e}")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
        all_news.sort(key=lambda x: x.get('published_parsed') or (0, 0, 0, 0, 0, 0), reverse=True)
        
        return all_news[:limit]
    
    def detect_language(self, text: str) -> str:
        """–ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return "unknown"
        
        # –†—É—Å—Å–∫–∏–µ –±—É–∫–≤—ã
        russian_chars = re.findall(r'[–∞-—è—ë–ê-–Ø–Å]', text)
        # –õ–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã
        latin_chars = re.findall(r'[a-zA-Z]', text)
        
        if len(russian_chars) > len(latin_chars):
            return "ru"
        elif len(latin_chars) > len(russian_chars):
            return "en"
        else:
            return "mixed"
    
    def format_news_message(self, news_list: List[Dict], show_categories: bool = True, show_translation: bool = True) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram"""
        if not news_list:
            return "üòî –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        
        message = "üì∞ *–ò–ù–§–û–ú–û–ù–ò–¢–û–† - –ü–û–°–õ–ï–î–ù–ò–ï –ù–û–í–û–°–¢–ò*\n\n"
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        categories = {}
        for news in news_list:
            category = news.get('category', '–æ–±—â–∏–µ')
            if category not in categories:
                categories[category] = []
            categories[category].append(news)
        
        for i, (category, category_news) in enumerate(categories.items(), 1):
            if show_categories:
                emoji = self.get_category_emoji(category)
                message += f"üìÇ *{emoji} {category.upper()}*\n\n"
            
            for j, news in enumerate(category_news, 1):
                if show_categories:
                    num = f"{i}.{j}"
                else:
                    num = str(i + j - 1)
                
                message += f"*{num}. {news['title']}*\n"
                message += f"üìù {news['description']}\n"
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —è–∑—ã–∫–µ –∏ –ø–µ—Ä–µ–≤–æ–¥–µ
                lang_info = ""
                if news.get('original_language') == 'en' and show_translation:
                    lang_info = " üá¨üáß (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)"
                elif news.get('original_language') == 'mixed' and show_translation:
                    lang_info = " üåç (—Å–º–µ—à–∞–Ω–Ω—ã–π)"
                
                message += f"üîó [–ß–∏—Ç–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é]({news['link']})\n"
                message += f"üì∞ –ò—Å—Ç–æ—á–Ω–∏–∫: {news['source']}{lang_info}\n"
                
                if news['published']:
                    message += f"üïê {news['published']}\n"
                message += "\n" + "‚îÄ" * 40 + "\n\n"
        
        message += f"üìä –ü–æ–∫–∞–∑–∞–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {len(news_list)} –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {', '.join(categories.keys())}"
        return message
    
    def get_category_emoji(self, category: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–æ–¥–∑–∏ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        emojis = {
            '–ø–æ–ª–∏—Ç–∏–∫–∞': 'üèõÔ∏è',
            '—ç–∫–æ–Ω–æ–º–∏–∫–∞': 'üí∞',
            '—Å–ø–æ—Ä—Ç': '‚öΩ',
            '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏': 'üíª',
            '–º–∏—Ä–æ–≤—ã–µ': 'üåç',
            '–æ–±—â–∏–µ': 'üìÑ'
        }
        return emojis.get(category, 'üì∞')
    
    def translate_text(self, text: str, target_lang: str = 'ru') -> Optional[str]:
        """–ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Å–µ—Ä–≤–∏—Å LibreTranslate"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É–±–ª–∏—á–Ω—ã–π –∏–Ω—Å—Ç–∞–Ω—Å LibreTranslate
            url = "https://libretranslate.de/translate"
            
            payload = {
                "q": text,
                "source": "auto",
                "target": target_lang,
                "format": "text"
            }
            
            response = requests.post(url, json=payload, timeout=10)
            
            if response.status_code == 200:
                result = response.json()
                return result.get('translatedText', text)
            else:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ —Ç–µ–∫—Å—Ç–∞: {e}")
            return None